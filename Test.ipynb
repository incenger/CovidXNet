{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import torch\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_features(x):\n",
    "    size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features\n",
    "class SimpNet(nn.Module):\n",
    "    def __init__(self, size_data, n_classes):\n",
    "        super(SimpNet, self).__init__()\n",
    "\n",
    "        self.size_data = np.copy(size_data)\n",
    "        self.conv1 = nn.Conv2d(1, 30, 3, stride=(1, 1), padding=(1, 1))\n",
    "        self.pool1 = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "\n",
    "\n",
    "        self.size_data //= 2\n",
    "\n",
    "        #####################\n",
    "        ####### Second ######\n",
    "        #####################\n",
    "        self.conv2 = nn.Conv2d(30, 60, 3, stride=(1, 1), padding=(1, 1))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "\n",
    "\n",
    "        self.size_data //= 2\n",
    "\n",
    "        ####################\n",
    "        ####### Third ######\n",
    "        ####################\n",
    "        self.conv3 = nn.Conv2d(60, 80, 3, stride=(1, 1), padding=(1, 1))\n",
    "        self.pool3 = nn.MaxPool2d((2, 2), stride=(2, 2))\n",
    "\n",
    "        self.size_data //= 2\n",
    "\n",
    "        #####################\n",
    "        ####### FC ##########\n",
    "        #####################\n",
    "        self.fc1 = nn.Linear(80*self.size_data[0]*self.size_data[1], 500)\n",
    "        \n",
    "        self.fc2 = nn.Linear(500, n_classes)\n",
    "        self.final = nn.Softmax(1)\n",
    "\n",
    "    def forward(self, image):\n",
    "\n",
    "        ####################\n",
    "        ####### First ######\n",
    "        ####################\n",
    "        image = self.pool1(F.relu(self.conv1(image)))\n",
    "\n",
    "\n",
    "        #####################\n",
    "        ####### Second ######\n",
    "        #####################\n",
    "        image = self.pool2(F.relu(self.conv2(image)))\n",
    "\n",
    "        ####################\n",
    "        ####### Third ######\n",
    "        ####################\n",
    "        image = self.pool3(F.relu(self.conv3(image)))\n",
    "      \n",
    "\n",
    "        #####################\n",
    "        ####### FC ##########\n",
    "        #####################\n",
    "        image = image.view(-1, flatten_features(image))\n",
    "\n",
    "        image = F.relu(self.fc1(image))\n",
    "        image = F.relu(self.fc2(image))\n",
    "\n",
    "        label = self.final(image)\n",
    "\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                               transforms.Grayscale(num_output_channels=1),\n",
    "                               transforms.ToTensor(),\n",
    "                               ])\n",
    "\n",
    "train_set = ImageFolder('./covidx_image_folder/train/', transform= transform)\n",
    "valid_set = ImageFolder('./covidx_image_folder/validation/', transform= transform)\n",
    "\n",
    "train_loader_folder = DataLoader(train_set, batch_size=24, shuffle=True)\n",
    "valid_loader_folder = DataLoader(valid_set, batch_size=24, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_figure(loss_train, loss_val, acc_train, acc_val, path):\n",
    "    plt.plot(loss_train, label='Loss Train')\n",
    "    plt.plot(loss_val, label='Loss Val')\n",
    "    plt.plot(acc_train, label='Acc Train')\n",
    "    plt.plot(acc_val, label='Acc Val')\n",
    "    plt.legend()\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, dict_of_values):\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'dict_of_values': dict_of_values}, os.path.join('.', 'model.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    N = len(data_loader.dataset)\n",
    "    start_time = time.time()\n",
    "    aLoss = 0\n",
    "    Acc = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "        image,label = batch\n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        aLoss += loss.item()\n",
    "        Acc += output.data.max(1)[1].eq(label.data).cpu().sum().numpy()\n",
    "       \n",
    "\n",
    "    aLoss /= (batch_idx + 1)\n",
    "    Acc /= N\n",
    "    print('Training: [Epoch %4d] loss: %.4f accuracy: %.4f lr: %.6f' % (epoch, aLoss, Acc, 0.001))\n",
    "    logger.info('Training: [Epoch %4d] loss: %.4f accuracy: %.4f lr: %.6f' % (epoch, aLoss, Acc, 0.001))\n",
    "\n",
    "    return aLoss, Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_epoch(epoch, model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    N = len(data_loader.dataset)\n",
    "    aLoss = 0\n",
    "    Acc = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "       \n",
    "        image,label = batch\n",
    "\n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        output = model(image)\n",
    "        pred = output.cpu().data.numpy()\n",
    "        pred_argmax = np.argmax(pred, axis=1)\n",
    "\n",
    "        aLoss += criterion(output, label).item()\n",
    "        Acc += output.data.max(1)[1].eq(label.data).cpu().sum().numpy()\n",
    "\n",
    "    aLoss /= (batch_idx + 1)\n",
    "    Acc /= N\n",
    "    print('Evaluation: [Epoch %4d] loss: %.4f accuracy: %.4f' % (epoch, aLoss, Acc))\n",
    "    logger.info('Evaluation: [Epoch %4d] loss: %.4f accuracy: %.4f' % (epoch, aLoss, Acc))\n",
    "\n",
    "    return pred_argmax, aLoss, Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader):\n",
    "    start_time = time.time()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=0.001, \n",
    "        momentum=0.5, \n",
    "        weight_decay=0.005, \n",
    "        nesterov=True\n",
    "    )\n",
    "\n",
    "    # For plot\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    acc_train = []\n",
    "    max_acc = -1\n",
    "    acc_val_ = 1\n",
    "    min_loss_train = 1000\n",
    "    min_loss_val = 1000\n",
    "    epoch_start = 1\n",
    "\n",
    "    for epoch in range(epoch_start, 5+1):\n",
    "\n",
    "        # Train and validation step and save loss and acc for plot\n",
    "        loss_train_, acc_train_ = train_epoch(epoch, model, train_loader, optimizer, criterion)\n",
    "        _, loss_val_, acc_val_ = validation_epoch(epoch, model, validation_loader, criterion)\n",
    "\n",
    "        loss_train.append(loss_train_)\n",
    "        acc_train.append(acc_train_)\n",
    "        loss_val.append(loss_val_)\n",
    "        acc_val.append(acc_val_)\n",
    "\n",
    "        #wait_change_lr += 1\n",
    "\n",
    "        # Best model saved\n",
    "        # if (acc_val_ > max_acc) or (acc_val_ >= max_acc and loss_train_ < min_loss_train):\n",
    "        if min_loss_val > loss_val_:\n",
    "            save_model(model, optimizer=optimizer, epoch=epoch, dict_of_values={'loss_train_': loss_train_, 'acc_train_': acc_train_, 'loss_val_': loss_val_, 'acc_val_': acc_val_})\n",
    "            max_acc = acc_val_\n",
    "            min_loss_val = loss_val_\n",
    "            min_loss_train = loss_train_\n",
    "\n",
    "\n",
    "    logger.info('Trained with %d epochs, lr = %g, batchsize = %d, momentum = %g with max validation accuracy of %.2f done in %s' %\\\n",
    "        (100, 0.001, 16,0.5, max_acc, datetime.timedelta(seconds=int(time.time() - start_time))))\n",
    "\n",
    "    make_train_figure(loss_train, loss_val, acc_train, acc_val, os.path.join('.', 'Train.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [05:22<00:00,  1.63it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [Epoch    1] loss: 1.0986 accuracy: 0.0367 lr: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [Epoch    1] loss: 1.0986 accuracy: 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [05:42<00:00,  1.53it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [Epoch    2] loss: 1.0986 accuracy: 0.0367 lr: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:29<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [Epoch    2] loss: 1.0986 accuracy: 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [05:43<00:00,  1.53it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [Epoch    3] loss: 1.0986 accuracy: 0.0367 lr: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:30<00:00,  1.94it/s]\n",
      "  0%|          | 0/524 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [Epoch    3] loss: 1.0986 accuracy: 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [05:35<00:00,  1.56it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [Epoch    4] loss: 1.0986 accuracy: 0.0367 lr: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:30<00:00,  1.91it/s]\n",
      "  0%|          | 0/524 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [Epoch    4] loss: 1.0986 accuracy: 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [05:43<00:00,  1.53it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [Epoch    5] loss: 1.0986 accuracy: 0.0367 lr: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:29<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [Epoch    5] loss: 1.0986 accuracy: 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6ea38bbf44db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-2953970e1640>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, validation_loader)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     logger.info('Trained with %d epochs, lr = %g, batchsize = %d, momentum = %g with max validation accuracy of %.2f done in %s' %\\\n\u001b[0;32m---> 47\u001b[0;31m         (100, 0.001, 16,0.5, max_acc, datetime.timedelta(seconds=int(time.time() - start_time))))\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmake_train_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "model = SimpNet(np.array([256,256]),3)\n",
    "model.cuda()\n",
    "train_model(model,train_loader_folder,valid_loader_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
